{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1j0SaNjc0t_r",
        "f1owX_Wj0-D3",
        "W8q-tRcS6Xgq",
        "Dde_wYBCOm6D",
        "WmjPHgRkOEoP",
        "RQlyH1daOS7Q",
        "XsuBVk7ZOb6M",
        "duHZOGNTzDKL",
        "7yFcJOauw86A",
        "a-LmN7Y3OwhS",
        "El70xjJ4KWgb",
        "QSge079PKeZw",
        "wuqeudByKltl",
        "ptQGZYhvy-qF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MD5 Light Algorithm"
      ],
      "metadata": {
        "id": "1j0SaNjc0t_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAsWQQtx0Wqn",
        "outputId": "c4d39f04-4369-4b6a-ab50-463e2dd4a292"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'00011011010100110111110010011110'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import math\n",
        "import struct\n",
        "\n",
        "class Hash_value:\n",
        "    def __init__(self, hashvalue_hexa):\n",
        "        self.hashvalue_hexa = hashvalue_hexa\n",
        "        self.hashvalue_bits = bin(int(hashvalue_hexa, 16))[2:].zfill(len(hashvalue_hexa) * 4)\n",
        "        self.hashvalue_integer =  int(hashvalue_hexa, 16)\n",
        "        self.hashvalue_bytes = bytes.fromhex(self.hashvalue_hexa)\n",
        "\n",
        "class MD5_Hash:\n",
        "    # Constructor (__init__)\n",
        "    def __init__(self, type = \"regular\"):\n",
        "        # Set all Variables and Constants dependend on wordsize_bit\n",
        "        if (type == \"regular\"):\n",
        "            self.wordsize_bit = 32\n",
        "            self.bits_length_rep = 'Q' # 64 bit / 8 Byte\n",
        "            self.padding_length = 64 - 8\n",
        "        elif (type == \"light\"):\n",
        "            self.wordsize_bit = 8\n",
        "            self.bits_length_rep = 'H' # 16 bit / 2 Byte\n",
        "            self.padding_length = 16 - 2\n",
        "        else: raise ValueError(\"hash type must be either light or regular\")\n",
        "        self.wordsize_byte = int(self.wordsize_bit / 8)\n",
        "        self.blocksize_byte = self.wordsize_byte * 16\n",
        "        self.hexa = (1 << (self.wordsize_byte * 8)) - 1\n",
        "        a0, b0, c0, d0 = 0x67452301, 0xEFCDAB89, 0x98BADCFE, 0x10325476\n",
        "        self.Ks = [int(abs(math.sin(i + 1)) * (2**self.wordsize_bit)) & self.hexa for i in range(64)]\n",
        "        self.Ss = list(map(lambda s: s % self.wordsize_bit,[7, 12, 17, 22] * 4 + [5, 9, 14, 20] * 4 + [4, 11, 16, 23] * 4 + [6, 10, 15, 21] * 4))\n",
        "        self.a0,self.b0,self.c0,self.d0 = map(lambda x: int(hex(x)[2:].upper()[:(self.wordsize_byte * 2)],16), [a0, b0, c0, d0])\n",
        "        self.hashlength_bit = 4* self.wordsize_bit\n",
        "        self.hashlength_byte = 4* self.wordsize_byte\n",
        "\n",
        "    #convert Type\n",
        "    def convertType(self,m):\n",
        "        if isinstance(m, bytes):\n",
        "            return m\n",
        "        # Make sure m is converted to byte value\n",
        "        if isinstance(m, str) and all(c in '01' for c in m):  # If input is a bit string\n",
        "            byte_length = (len(m) + 7) // 8  # Compute required byte length\n",
        "            return int(m, 2).to_bytes(byte_length, byteorder=\"big\")\n",
        "        elif isinstance(m, str):  # If input is a message (string)\n",
        "            return m.encode('utf-8') # bytes\n",
        "        else:\n",
        "            raise ValueError(\"Input must be either a message (string) or a valid bit string.\")\n",
        "\n",
        "    #Padding Function\n",
        "    def pad(self,m):\n",
        "        bytes = self.convertType(m)\n",
        "        original_length_bits = len(bytes) * 8\n",
        "        bytes += b'\\x80' #appends 10000000\n",
        "        while len(bytes)%(self.blocksize_byte)!=self.padding_length:\n",
        "            bytes += b'\\x00' #appends 00000000\n",
        "        bytes += struct.pack(f'<{self.bits_length_rep}', original_length_bits) # appends 16 bit /64 bit representation in litte-endian-format of length\n",
        "        return bytes\n",
        "\n",
        "    # Rotation function (rotate left)\n",
        "    def rotate_left(self, x, n):\n",
        "        # Perform a left rotation on a 32-bit integer 'x' by 'n' positions\n",
        "        x &= self.hexa\n",
        "        return ((x << n) | (x >> (self.wordsize_bit - n))) & self.hexa\n",
        "\n",
        "    #digest\n",
        "    def digestABCD(self, A,B,C,D):\n",
        "        raw = sum(value << (self.wordsize_bit * i) for i, value in enumerate([A,B,C,D])).to_bytes(16, byteorder='little')\n",
        "        hashvalue_hexa = '{:0{width}x}'.format(int.from_bytes(raw[:self.hashlength_byte], byteorder='big'), width = self.wordsize_bit)\n",
        "        hv = Hash_value(hashvalue_hexa)\n",
        "        return Hash_value(hashvalue_hexa)\n",
        "\n",
        "    #Hash\n",
        "    def processblock(self, block, inits):\n",
        "        A, B, C, D = inits\n",
        "        for i in range(64):\n",
        "            if i <= 15:\n",
        "                f = (B & C) | (~B & D)\n",
        "                g = i\n",
        "            elif i <= 31:\n",
        "                f = (B & D) | (C & ~D)\n",
        "                g = (5 * i + 1) % 16\n",
        "            elif i <= 47:\n",
        "                f = B ^ C ^ D\n",
        "                g = (3 * i + 5) % 16\n",
        "            elif i <= 63:\n",
        "                f = C ^ (B | ~D)\n",
        "                g = (7 * i) % 16\n",
        "\n",
        "            # Calculate the temporary values\n",
        "            temp = D\n",
        "            D = C\n",
        "            C = B\n",
        "            M = int.from_bytes(block[self.wordsize_byte * g : self.wordsize_byte * g + self.wordsize_byte], byteorder='little')\n",
        "            B = (B + self.rotate_left(A + f + self.Ks[i] + M, self.Ss[i])) & self.hexa\n",
        "            A = temp\n",
        "        return([A,B,C,D])\n",
        "\n",
        "    def digest(self,m):\n",
        "        blocks = self.pad(m)\n",
        "        # Process each block\n",
        "        A_final,B_final,C_final,D_final = self.a0, self.b0, self.c0, self.d0\n",
        "        for offset in range(0, len(blocks), self.blocksize_byte):\n",
        "            block = blocks[ offset : offset + self.blocksize_byte]\n",
        "\n",
        "            #Compute Hash\n",
        "            A,B,C,D = self.processblock(block, [A_final,B_final,C_final,D_final])\n",
        "            A_final, B_final, C_final, D_final = (A_final + A) & self.hexa, (B_final + B) & self.hexa, (C_final + C) & self.hexa, (D_final + D) & self.hexa\n",
        "        return self.digestABCD(A_final, B_final, C_final, D_final)\n",
        "\n",
        "#check correctness by comparing with md5 library\n",
        "import hashlib\n",
        "bytedata = \"Hello World!\".encode('utf-8')\n",
        "md5_hash = hashlib.md5(bytedata).digest()\n",
        "computed_hash = MD5_Hash().digest(bytedata).hashvalue_bytes\n",
        "if (md5_hash != computed_hash):\n",
        "    print(f\"Correct hash:  {md5_hash}\")\n",
        "    print(f\"Computed hash: {computed_hash}\")\n",
        "\n",
        "def md5_light(input_data: str) -> str:\n",
        "    # use MD5 - light to calculate hash\n",
        "    Hash = MD5_Hash('light')\n",
        "    hashvalue = Hash.digest(input_data)\n",
        "    return hashvalue.hashvalue_bits\n",
        "\n",
        "md5_light(\"hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Dataset"
      ],
      "metadata": {
        "id": "f1owX_Wj0-D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to Google Drive\n",
        "file_path = '/content/drive/MyDrive/Datasets/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ6GIS_D531R",
        "outputId": "167f6217-39a8-4afd-e87b-8400284677f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset for FFN\n",
        "- Features: hash as normed integer\n",
        "- Label: message as bitvector"
      ],
      "metadata": {
        "id": "PtrN8rXT32ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import struct\n",
        "\n",
        "# MD5 Light, returning integer\n",
        "def H(m) -> int:\n",
        "    return MD5_Hash('light').digest(m).hashvalue_integer\n",
        "\n",
        "def generate_bitstring(length):\n",
        "    return ''.join(random.choice('01') for _ in range(length))\n",
        "\n",
        "def generate_random_bitstrings(num_samples, bitlength):\n",
        "    bitstrings = set()\n",
        "    while(len(bitstrings) < num_samples):\n",
        "        bitstring = generate_bitstring(bitlength)\n",
        "        bitstrings.add(bitstring)\n",
        "    return bitstrings\n",
        "\n",
        "def generate_dataset(num_samples=100000, msglength = 104):# 104 bit messages are processed in one block\n",
        "    X = []  # Input (normalized Hashvalues)\n",
        "    Y = []  # Output (128-Bit-Bitvectors)\n",
        "    msgs = generate_random_bitstrings(num_samples, msglength)\n",
        "    for msg in msgs:\n",
        "        hash_value = H(msg)  # calculate 32-Bit-Hash\n",
        "        hash_normalized = hash_value / (2**32 - 1)  # Normalized to [0,1]\n",
        "        msg_bits = np.array(list(msg), dtype=np.uint8)  # 128 Bit\n",
        "\n",
        "        X.append([hash_normalized])\n",
        "        Y.append(msg_bits)\n",
        "\n",
        "    X = np.array(X, dtype=np.float32)\n",
        "    Y = np.array(Y, dtype=np.float32)\n",
        "\n",
        "    np.save(f\"{file_path}X_FFN_MD5light.npy\", X)\n",
        "    np.save(f\"{file_path}Y_FFN_MD5light.npy\", Y)\n",
        "\n",
        "\n",
        "generate_dataset(1000000)"
      ],
      "metadata": {
        "id": "ptbxHBkJ0ybP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras scikit-optimize"
      ],
      "metadata": {
        "id": "m87xtgwVBCcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feedforward Neural Network Based Pre Image Attack on MD5 Light\n"
      ],
      "metadata": {
        "id": "W8q-tRcS6Xgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "KVqgkT146jbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load Dataset\n",
        "X = np.load(f\"{file_path}X_FFN_MD5light.npy\")  # Normalisierte Hashwerte\n",
        "Y = np.load(f\"{file_path}Y_FFN_MD5light.npy\")  # 104-Bit-Nachrichten als Bitvektoren\n",
        "\n",
        "# Überprüfen der Datenform\n",
        "print(f\"X Shape: {X.shape}\")  # (100000, 1)\n",
        "print(f\"Y Shape: {Y.shape}\")  # (100000, 104)\n",
        "\n",
        "# 80% Training, 20% Test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQrMXuGP6W0P",
        "outputId": "f868d706-a11e-41a2-8d39-72205c9e8441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Shape: (1000000, 1)\n",
            "Y Shape: (1000000, 104)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 256-512-256 Hidden Layers mit ReLU für nichtlineare Transformationen.\n",
        "- 128 Output-Neuronen mit Sigmoid, um bitweise Vorhersagen zwischen 0 und 1 zu machen.\n",
        "- Binary Cross-Entropy Loss, weil wir eine bitweise Klassifikation machen."
      ],
      "metadata": {
        "id": "PgBE32N27fXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import time\n",
        "import tracemalloc\n",
        "from colorama import Fore, Style\n",
        "\n",
        "# === Define the Network ===\n",
        "\n",
        "# Hyperparameters to use\n",
        "num_layers = 4\n",
        "neurons = 384\n",
        "learning_rate = 0.000012\n",
        "dropout_rate = 0.3425\n",
        "batch_size = 736\n",
        "activation = \"relu\"\n",
        "\n",
        "#Leaky relu\n",
        "if activation == \"leaky_relu\":\n",
        "    activation_func = layers.LeakyReLU()\n",
        "else:\n",
        "  activation_func = activation\n",
        "\n",
        " # === Build CNN Model ===\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1,)))\n",
        "model.add(Dense(neurons, activation=activation_func))\n",
        "model.add(Dropout(dropout_rate))\n",
        "\n",
        "for _ in range(num_layers - 1):\n",
        "    model.add(Dense(neurons, activation=activation_func))\n",
        "\n",
        "model.add(Dense(104, activation=\"sigmoid\"))  # Bitvektor als Ausgabe\n",
        "# === Compile Model ===\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "zQdKuJdb6qTv",
        "outputId": "3b8c0bb9-0d0c-4f35-c0b0-94fe351fa619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)                 │             \u001b[38;5;34m768\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)                 │         \u001b[38;5;34m147,840\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)                 │         \u001b[38;5;34m147,840\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)                 │         \u001b[38;5;34m147,840\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m104\u001b[0m)                 │          \u001b[38;5;34m40,040\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,840</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,840</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,840</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">40,040</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m484,328\u001b[0m (1.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">484,328</span> (1.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m484,328\u001b[0m (1.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">484,328</span> (1.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Track Time and Memory Usage ===\n",
        "tracemalloc.start()\n",
        "start_time = time.time()\n",
        "\n",
        "# === Train model ===\n",
        "early_stopping = EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)\n",
        "history = model.fit(X_train, Y_train, epochs=50, batch_size=batch_size, validation_data=(X_test, Y_test), callbacks = [early_stopping])\n",
        "\n",
        "# === Output Time taken and memory used ===\n",
        "_, peak = tracemalloc.get_traced_memory()  # Memory in bytes\n",
        "tracemalloc.stop() # Stop tracking\n",
        "elapsed_time = time.time() - start_time\n",
        "print(Fore.RED + f\"Time taken: {(elapsed_time / 60):.2f}min\" + Style.RESET_ALL)\n",
        "print(Fore.GREEN + f\"Memory Used: {peak:.2f} MB\" + Style.RESET_ALL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO_bql7t7lXJ",
        "outputId": "e59b7a42-88d3-4c4b-c8ff-dc302729d870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 71ms/step - accuracy: 0.0051 - loss: 0.6932 - val_accuracy: 1.1500e-04 - val_loss: 0.6931\n",
            "Epoch 2/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 71ms/step - accuracy: 0.0129 - loss: 0.6932 - val_accuracy: 0.0000e+00 - val_loss: 0.6931\n",
            "Epoch 3/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.0053 - loss: 0.6931 - val_accuracy: 0.0000e+00 - val_loss: 0.6931\n",
            "Epoch 4/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 73ms/step - accuracy: 0.0065 - loss: 0.6931 - val_accuracy: 0.0000e+00 - val_loss: 0.6931\n",
            "Epoch 5/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.0033 - loss: 0.6931 - val_accuracy: 1.0000e-05 - val_loss: 0.6931\n",
            "Epoch 6/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.0035 - loss: 0.6931 - val_accuracy: 4.5000e-05 - val_loss: 0.6931\n",
            "Epoch 7/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 73ms/step - accuracy: 0.0025 - loss: 0.6931 - val_accuracy: 6.0000e-05 - val_loss: 0.6931\n",
            "Epoch 8/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.0021 - loss: 0.6931 - val_accuracy: 2.5000e-05 - val_loss: 0.6931\n",
            "Epoch 9/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 71ms/step - accuracy: 8.8744e-04 - loss: 0.6931 - val_accuracy: 3.0000e-05 - val_loss: 0.6931\n",
            "Epoch 10/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 73ms/step - accuracy: 0.0010 - loss: 0.6931 - val_accuracy: 3.0000e-05 - val_loss: 0.6931\n",
            "Epoch 11/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.0013 - loss: 0.6931 - val_accuracy: 5.5000e-05 - val_loss: 0.6931\n",
            "Epoch 12/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 70ms/step - accuracy: 0.0012 - loss: 0.6931 - val_accuracy: 3.5000e-05 - val_loss: 0.6931\n",
            "Epoch 13/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 6.4634e-04 - loss: 0.6931 - val_accuracy: 5.0000e-05 - val_loss: 0.6931\n",
            "Epoch 14/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 69ms/step - accuracy: 0.0012 - loss: 0.6931 - val_accuracy: 4.0000e-05 - val_loss: 0.6931\n",
            "Epoch 15/50\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 75ms/step - accuracy: 0.0011 - loss: 0.6931 - val_accuracy: 4.0000e-05 - val_loss: 0.6931\n",
            "\u001b[31mTime taken: 20.49min\u001b[0m\n",
            "\u001b[32mMemory Used: 336778850.00 MB\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Optimization"
      ],
      "metadata": {
        "id": "duHZOGNTzDKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import time\n",
        "import tracemalloc\n",
        "from colorama import Fore, Style\n",
        "\n",
        "# Daten laden\n",
        "X = np.load(f\"{file_path}X_FFN_MD5light.npy\")\n",
        "Y = np.load(f\"{file_path}Y_FFN_MD5light.npy\")\n",
        "\n",
        "# Train-Test-Split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "historys = []\n",
        "params_ = []\n",
        "trial_times = []\n",
        "trial_memory = []\n",
        "\n",
        "# Ziel-Funktion für Optuna\n",
        "def objective(trial):\n",
        "    # === Track Time and Memory Usage ===\n",
        "    tracemalloc.start()\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Optimierbare Hyperparameter\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 2, 5, step = 1)\n",
        "    neurons = trial.suggest_int(\"neurons\", 128, 1024, step=128)\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
        "    batch_size = trial.suggest_int(\"batch_size\", 32, 1024, step=32)\n",
        "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"leaky_relu\",\"selu\"])\n",
        "    dropout_rate = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "\n",
        "     #Leaky relu\n",
        "    if activation == \"leaky_relu\":\n",
        "        activation_func = LeakyReLU()\n",
        "    else:\n",
        "      activation_func = activation\n",
        "\n",
        "    # Modell aufbauen\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(1,)))\n",
        "    model.add(Dense(neurons, activation=activation_func))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    for _ in range(num_layers - 1):\n",
        "        model.add(Dense(neurons, activation=activation_func))\n",
        "\n",
        "    model.add(Dense(104, activation=\"sigmoid\"))  # Bitvektor als Ausgabe\n",
        "\n",
        "    # Optimizer\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    # EarlyStopping Callback erstellen\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=50, batch_size=batch_size, verbose=0, callbacks = [early_stopping])\n",
        "    historys.append(history)\n",
        "    params_.append([num_layers,neurons,learning_rate,batch_size,activation, dropout_rate])\n",
        "\n",
        "    _, peak = tracemalloc.get_traced_memory()  # Memory in bytes\n",
        "    tracemalloc.stop() # Stop tracking\n",
        "    elapsed_time = time.time() - start_time\n",
        "    trial_times.append(elapsed_time)\n",
        "    trial_memory.append(peak / 1e6)\n",
        "\n",
        "    # Bewertung auf Testset\n",
        "    val_loss = history.history['val_loss'][-1]\n",
        "\n",
        "    return val_loss   # Wir minimieren loss\n",
        "\n",
        "# === Run Optuna Optimization ===\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# === Print best hyperparameters ===\n",
        "print(Fore.CYAN + f\"\\nBest Hyperparameters: {study.best_params}\" + Style.RESET_ALL)\n",
        "\n",
        "# === Output Time taken and memory used ===\n",
        "print(Fore.RED + f\"Total Time taken: {(sum(trial_times)/60):.2f}min\" + Style.RESET_ALL)\n",
        "print(Fore.YELLOW + f\"Average Time Per Trial: {sum(trial_times)/len(trial_times):.2f}s\" + Style.RESET_ALL)\n",
        "print(Fore.GREEN + f\"Average Memory Used: {sum(trial_memory)/len(trial_memory):.2f} MB\" + Style.RESET_ALL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62431800-4285-4262-bec6-1f60a45743a7",
        "id": "-9CDcBT1zDKM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-08 11:41:34,503] A new study created in memory with name: no-name-324f2def-4682-45e2-8d89-ca47ad34373c\n",
            "<ipython-input-8-0d47339909e6>:35: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
            "[I 2025-02-08 11:42:17,809] Trial 0 finished with value: 0.6931566596031189 and parameters: {'num_layers': 2, 'neurons': 128, 'learning_rate': 0.0010594973952916386, 'batch_size': 928, 'activation': 'relu', 'dropout': 0.37710729289718314}. Best is trial 0 with value: 0.6931566596031189.\n",
            "[I 2025-02-08 11:48:07,236] Trial 1 finished with value: 0.6931626200675964 and parameters: {'num_layers': 2, 'neurons': 768, 'learning_rate': 2.6177986266633664e-05, 'batch_size': 256, 'activation': 'selu', 'dropout': 0.46737891480278193}. Best is trial 0 with value: 0.6931566596031189.\n",
            "[I 2025-02-08 12:24:53,569] Trial 2 finished with value: 0.6936487555503845 and parameters: {'num_layers': 3, 'neurons': 896, 'learning_rate': 0.0010787913955407527, 'batch_size': 64, 'activation': 'selu', 'dropout': 0.12483081308625295}. Best is trial 0 with value: 0.6931566596031189.\n",
            "[I 2025-02-08 12:26:53,903] Trial 3 finished with value: 0.6931540966033936 and parameters: {'num_layers': 4, 'neurons': 128, 'learning_rate': 1.4225414527764856e-05, 'batch_size': 672, 'activation': 'relu', 'dropout': 0.2190616904711097}. Best is trial 3 with value: 0.6931540966033936.\n",
            "[I 2025-02-08 12:55:39,823] Trial 4 finished with value: 0.6931602358818054 and parameters: {'num_layers': 5, 'neurons': 1024, 'learning_rate': 0.00025945016827482885, 'batch_size': 224, 'activation': 'leaky_relu', 'dropout': 0.24667814734139606}. Best is trial 3 with value: 0.6931540966033936.\n",
            "[I 2025-02-08 13:07:23,860] Trial 5 finished with value: 0.6931672096252441 and parameters: {'num_layers': 3, 'neurons': 640, 'learning_rate': 1.1258054768285592e-05, 'batch_size': 288, 'activation': 'selu', 'dropout': 0.49448542276996854}. Best is trial 3 with value: 0.6931540966033936.\n",
            "[I 2025-02-08 13:11:40,541] Trial 6 finished with value: 0.69315505027771 and parameters: {'num_layers': 3, 'neurons': 768, 'learning_rate': 9.217067955201453e-05, 'batch_size': 640, 'activation': 'leaky_relu', 'dropout': 0.23147851868213412}. Best is trial 3 with value: 0.6931540966033936.\n",
            "[I 2025-02-08 13:18:15,722] Trial 7 finished with value: 0.6931777596473694 and parameters: {'num_layers': 2, 'neurons': 768, 'learning_rate': 0.0001568007583253206, 'batch_size': 256, 'activation': 'selu', 'dropout': 0.30447032663606144}. Best is trial 3 with value: 0.6931540966033936.\n",
            "[I 2025-02-08 13:25:19,813] Trial 8 finished with value: 0.693155825138092 and parameters: {'num_layers': 3, 'neurons': 1024, 'learning_rate': 3.88982845257007e-05, 'batch_size': 384, 'activation': 'leaky_relu', 'dropout': 0.19416558520644156}. Best is trial 3 with value: 0.6931540966033936.\n",
            "[I 2025-02-08 13:57:37,183] Trial 9 finished with value: 0.6931665539741516 and parameters: {'num_layers': 5, 'neurons': 768, 'learning_rate': 5.910121409458788e-05, 'batch_size': 832, 'activation': 'selu', 'dropout': 0.462580527674182}. Best is trial 3 with value: 0.6931540966033936.\n",
            "[I 2025-02-08 13:58:28,779] Trial 10 finished with value: 0.693168044090271 and parameters: {'num_layers': 4, 'neurons': 128, 'learning_rate': 0.005108515464229392, 'batch_size': 640, 'activation': 'relu', 'dropout': 0.13324272557043054}. Best is trial 3 with value: 0.6931540966033936.\n",
            "[I 2025-02-08 14:00:47,970] Trial 11 finished with value: 0.6931533813476562 and parameters: {'num_layers': 4, 'neurons': 384, 'learning_rate': 1.1202001286157447e-05, 'batch_size': 640, 'activation': 'leaky_relu', 'dropout': 0.26438761122196897}. Best is trial 11 with value: 0.6931533813476562.\n",
            "[I 2025-02-08 14:03:20,490] Trial 12 finished with value: 0.6931514143943787 and parameters: {'num_layers': 4, 'neurons': 384, 'learning_rate': 1.1737794583316627e-05, 'batch_size': 736, 'activation': 'relu', 'dropout': 0.34251688664150143}. Best is trial 12 with value: 0.6931514143943787.\n",
            "[I 2025-02-08 14:05:38,494] Trial 13 finished with value: 0.6931542754173279 and parameters: {'num_layers': 4, 'neurons': 384, 'learning_rate': 1.3308498422918166e-05, 'batch_size': 800, 'activation': 'leaky_relu', 'dropout': 0.3564384975274331}. Best is trial 12 with value: 0.6931514143943787.\n",
            "[I 2025-02-08 14:08:26,977] Trial 14 finished with value: 0.6931540966033936 and parameters: {'num_layers': 5, 'neurons': 384, 'learning_rate': 0.0008676922998490288, 'batch_size': 480, 'activation': 'relu', 'dropout': 0.31336662436959056}. Best is trial 12 with value: 0.6931514143943787.\n",
            "[I 2025-02-08 14:10:36,142] Trial 15 finished with value: 0.693152666091919 and parameters: {'num_layers': 4, 'neurons': 384, 'learning_rate': 3.13161684670362e-05, 'batch_size': 992, 'activation': 'leaky_relu', 'dropout': 0.40078612146488424}. Best is trial 12 with value: 0.6931514143943787.\n",
            "[I 2025-02-08 14:13:47,062] Trial 16 finished with value: 0.6931518316268921 and parameters: {'num_layers': 4, 'neurons': 512, 'learning_rate': 3.257651895643125e-05, 'batch_size': 992, 'activation': 'relu', 'dropout': 0.406392611421468}. Best is trial 12 with value: 0.6931514143943787.\n",
            "[I 2025-02-08 14:18:04,918] Trial 17 finished with value: 0.6931543946266174 and parameters: {'num_layers': 5, 'neurons': 512, 'learning_rate': 0.00010560930853678493, 'batch_size': 864, 'activation': 'relu', 'dropout': 0.42311713794252837}. Best is trial 12 with value: 0.6931514143943787.\n",
            "[I 2025-02-08 14:20:50,912] Trial 18 finished with value: 0.6931518316268921 and parameters: {'num_layers': 4, 'neurons': 512, 'learning_rate': 2.822394282414974e-05, 'batch_size': 1024, 'activation': 'relu', 'dropout': 0.34054831266229707}. Best is trial 12 with value: 0.6931514143943787.\n",
            "[I 2025-02-08 14:21:53,296] Trial 19 finished with value: 0.6931596398353577 and parameters: {'num_layers': 3, 'neurons': 256, 'learning_rate': 0.0004895719745879037, 'batch_size': 768, 'activation': 'relu', 'dropout': 0.41843761278744823}. Best is trial 12 with value: 0.6931514143943787.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m\n",
            "Best Hyperparameters: {'num_layers': 4, 'neurons': 384, 'learning_rate': 1.1737794583316627e-05, 'batch_size': 736, 'activation': 'relu', 'dropout': 0.34251688664150143}\u001b[0m\n",
            "\u001b[31mTotal Time taken: 160.31min\u001b[0m\n",
            "\u001b[33mAverage Time Per Trial: 480.93s\u001b[0m\n",
            "\u001b[32mAverage Memory Used: 45.25 MB\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations\n"
      ],
      "metadata": {
        "id": "rmV2LTg8Vmhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0FLGE4CVra_",
        "outputId": "2f55615d-c7b2-4aa1-89ed-c9bc3bc4a4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvEXoxEFVn1r",
        "outputId": "10a9697e-b9f9-4ee0-b912-d3d26ef29808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.4/383.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.0\n"
          ]
        }
      ]
    }
  ]
}