{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1j0SaNjc0t_r",
        "f1owX_Wj0-D3",
        "W8q-tRcS6Xgq",
        "Dde_wYBCOm6D",
        "WmjPHgRkOEoP",
        "RQlyH1daOS7Q",
        "XsuBVk7ZOb6M",
        "duHZOGNTzDKL",
        "7yFcJOauw86A",
        "a-LmN7Y3OwhS",
        "El70xjJ4KWgb",
        "QSge079PKeZw",
        "wuqeudByKltl",
        "ptQGZYhvy-qF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Hash"
      ],
      "metadata": {
        "id": "1j0SaNjc0t_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "simple modulo hash function:\n",
        "$$\n",
        "    f(x) = x\\mod c\\text{, where }x \\geq 0\\text{, and }c = 2^{32} - 1.\n",
        "$$"
      ],
      "metadata": {
        "id": "9yDEqouz8cSO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAsWQQtx0Wqn",
        "outputId": "ce65020d-4bf1-4ab1-bf7c-af32715bbd0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00000111010110111100110100011101\n",
            "123456797\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import struct\n",
        "\n",
        "c = 2**32 - 1\n",
        "\n",
        "class Hash_value:\n",
        "    def __init__(self, hashvalue):\n",
        "        self.bits = format(hashvalue,'b').zfill(32)\n",
        "        self.integer =  hashvalue\n",
        "\n",
        "def simple_digest(m):\n",
        "  if isinstance(m, str) and all(c in '01' for c in m):  # If input is a bit string\n",
        "    m = int(m,2)\n",
        "  elif not isinstance(m, int):\n",
        "    raise ValueError(\"Input must be a bit string or integer\")\n",
        "  return Hash_value((m + 8) % c)\n",
        "\n",
        "\n",
        "print(simple_digest(123456789).bits)\n",
        "print(simple_digest(123456789).integer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Dataset"
      ],
      "metadata": {
        "id": "f1owX_Wj0-D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to Google Drive\n",
        "file_path = '/content/drive/MyDrive/Datasets/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ6GIS_D531R",
        "outputId": "cf7ad812-70aa-4ee6-e0b9-00b288094873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset for FFN\n",
        "- Input: hash as normed integer\n",
        "- Output: message as bitvector"
      ],
      "metadata": {
        "id": "PtrN8rXT32ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import struct\n",
        "\n",
        "def H(m):\n",
        "    return simple_digest(m)\n",
        "\n",
        "def generate_bitstring(length):\n",
        "    return format(random.randint(0,c - 1),'b').zfill(104)\n",
        "\n",
        "def generate_random_bitstrings(num_samples, bitlength):\n",
        "    bitstrings = set()\n",
        "    while(len(bitstrings) < num_samples):\n",
        "        bitstring = generate_bitstring(bitlength)\n",
        "        bitstrings.add(bitstring)\n",
        "    return bitstrings\n",
        "\n",
        "def generate_dataset(num_samples=100000, msglength = 104):# 104 bit messages are processed in one block\n",
        "    X = []  # Input (normalized Hashvalues)\n",
        "    Y_int = []\n",
        "    Y = []  # Output (128-Bit-Bitvectors)\n",
        "    msgs = generate_random_bitstrings(num_samples, msglength)\n",
        "    for msg in msgs:\n",
        "        hash = H(msg)  # calculate 32-Bit-Hash\n",
        "        hash_normalized = hash.integer / (2**32 - 1)  # Normalized to [0,1]\n",
        "        msg_bits = np.array(list(msg), dtype=np.uint8)  # 128 Bit\n",
        "\n",
        "        X.append([hash_normalized])\n",
        "        Y.append(msg_bits)\n",
        "        Y_int.append([int(msg,2)/c])\n",
        "\n",
        "    X = np.array(X, dtype=np.float32)\n",
        "    Y = np.array(Y, dtype=np.float32)\n",
        "    Y_int = np.array(Y_int, dtype=np.float32)\n",
        "\n",
        "    np.save(f\"{file_path}X_FFN_simpleHash.npy\", X)\n",
        "    np.save(f\"{file_path}Y_FFN_simpleHash.npy\", Y)\n",
        "    np.save(f\"{file_path}Y_int_FFN_simpleHash.npy\", Y_int)\n",
        "\n",
        "\n",
        "generate_dataset(100000)"
      ],
      "metadata": {
        "id": "ptbxHBkJ0ybP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset for CNN\n",
        "- Features: hash as bitvector\n",
        "- Label: message as bitvector"
      ],
      "metadata": {
        "id": "zyrNbJJDwRp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import struct\n",
        "\n",
        "# MD5 Light, returning integer\n",
        "def H(m) -> str:\n",
        "    return simple_digest(m).bits\n",
        "\n",
        "def generate_bitstring(length):\n",
        "    return ''.join(random.choice('01') for _ in range(length))\n",
        "\n",
        "def generate_random_bitstrings(num_samples, bitlength):\n",
        "    bitstrings = set()\n",
        "    while(len(bitstrings) < num_samples):\n",
        "        bitstring = generate_bitstring(bitlength)\n",
        "        bitstrings.add(bitstring)\n",
        "    return bitstrings\n",
        "\n",
        "def generate_dataset(num_samples=100000, msglength = 104):# 104 bit messages are processed in one block\n",
        "    X = []  # Input (32-Bit-Vectors)\n",
        "    Y = []  # Output (128-Bit-Bitvectors)\n",
        "    msgs = generate_random_bitstrings(num_samples, msglength)\n",
        "    for msg in msgs:\n",
        "        hash = H(msg)  # calculate 32-Bit-Hash\n",
        "        hash_bits = np.array(list(hash), dtype=np.uint8)  # 32 Bit\n",
        "        msg_bits = np.array(list(msg), dtype=np.uint8)  # 128 Bit\n",
        "\n",
        "        X.append(hash_bits)\n",
        "        Y.append(msg_bits)\n",
        "\n",
        "    X = np.array(X, dtype=np.float32)\n",
        "    Y = np.array(Y, dtype=np.float32)\n",
        "\n",
        "    np.save(f\"{file_path}X_CNN_simpleHash.npy\", X)\n",
        "    np.save(f\"{file_path}Y_CNN_simpleHash.npy\", Y)\n",
        "\n",
        "\n",
        "generate_dataset(100000)"
      ],
      "metadata": {
        "id": "-SAgWQ4HwSHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m87xtgwVBCcc",
        "outputId": "a23c3d2e-de08-4455-bbac-808f3ffa8552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize, scikeras\n",
            "Successfully installed pyaml-25.1.0 scikeras-0.13.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feedforward Neural Network Based Pre Image Attack on MD5 Light\n"
      ],
      "metadata": {
        "id": "W8q-tRcS6Xgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "KVqgkT146jbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load Dataset\n",
        "X = np.load(f\"{file_path}X_FFN_simpleHash.npy\")  # Normalisierte Hashwerte\n",
        "Y = np.load(f\"{file_path}Y_FFN_simpleHash.npy\")  # 104-Bit-Nachrichten als Bitvektoren\n",
        "Y_int = np.load(f\"{file_path}Y_int_FFN_simpleHash.npy\")  # 104-Bit-Nachrichten als Integer\n",
        "\n",
        "# Überprüfen der Datenform\n",
        "print(f\"X Shape: {X.shape}\")  # (100000, 1)\n",
        "print(f\"Y Shape: {Y.shape}\")  # (100000, 104)\n",
        "print(f\"Y_int Shape: {Y_int.shape}\")  # (100000, 104)\n",
        "\n",
        "# 80% Training, 20% Test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_int, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQrMXuGP6W0P",
        "outputId": "022aa1b7-040e-4732-9fbe-0d5514f51cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Shape: (100000, 1)\n",
            "Y Shape: (100000, 104)\n",
            "Y_int Shape: (100000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Architectur:\n",
        "Since the function is periodic and simple, a small fully connected neural network with ReLU activation should work."
      ],
      "metadata": {
        "id": "PgBE32N27fXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modellaufbau\n",
        "def create_model(learning_rate=0.005, neurons=[256,512,256], activation_fct='relu', dropout_rate=0.2):\n",
        "  model = Sequential([\n",
        "    Input(shape=(1,)), # Input Layer\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),  # Hidden layer\n",
        "    #Dense(104, activation=\"sigmoid\")  # 128 Neuronen, Sigmoid für bitweise Ausgabe\n",
        "    Dense(1)  # Output layer\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mse\", metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "model = create_model()\n",
        "# Modellübersicht\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "zQdKuJdb6qTv",
        "outputId": "44a26844-dfe3-49f7-cab1-7d6cf305d773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,241\u001b[0m (8.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,241</span> (8.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,241\u001b[0m (8.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,241</span> (8.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modell trainieren\n",
        "history = model.fit(X_train, Y_train, epochs=20, batch_size=64, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO_bql7t7lXJ",
        "outputId": "099291ad-7385-461c-f0a0-8ca3b1925501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0160 - val_accuracy: 0.0000e+00 - val_loss: 5.6407e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 5.2053e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.0229e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 4.1555e-04 - val_accuracy: 0.0000e+00 - val_loss: 3.5598e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 3.6304e-04 - val_accuracy: 0.0000e+00 - val_loss: 3.1918e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 3.3935e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.9428e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 3.1358e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.7496e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 3.1137e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.5957e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 2.8744e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.6668e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 2.8097e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.4207e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 2.5387e-04 - val_accuracy: 0.0000e+00 - val_loss: 3.9150e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 2.5902e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.2645e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 2.5268e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.1403e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 2.4134e-04 - val_accuracy: 0.0000e+00 - val_loss: 3.1117e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 2.2762e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.9876e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 2.3024e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.9378e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 2.2231e-04 - val_accuracy: 0.0000e+00 - val_loss: 2.3012e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 2.2198e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.8263e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 2.2252e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.8025e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 2.0790e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.7758e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 2.0501e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.8878e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Optimization"
      ],
      "metadata": {
        "id": "duHZOGNTzDKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Daten laden\n",
        "X = np.load(f\"{file_path}X_FFN_MD5light.npy\")\n",
        "Y = np.load(f\"{file_path}Y_FFN_MD5light.npy\")\n",
        "\n",
        "# Train-Test-Split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "historys = []\n",
        "params_ = []\n",
        "\n",
        "# Ziel-Funktion für Optuna\n",
        "def objective(trial):\n",
        "    # Optimierbare Hyperparameter\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 5)\n",
        "    neurons = trial.suggest_int(\"neurons\", 128, 1024, step=128)\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
        "    batch_size = trial.suggest_int(\"batch_size\", 32, 1024, step=32)\n",
        "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"leaky_relu\"])\n",
        "\n",
        "    # Modell aufbauen\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(1,)))\n",
        "    model.add(Dense(neurons, activation=activation))\n",
        "\n",
        "    for _ in range(num_layers - 1):\n",
        "        model.add(Dense(neurons, activation=activation))\n",
        "\n",
        "    model.add(Dense(104, activation=\"sigmoid\"))  # Bitvektor als Ausgabe\n",
        "\n",
        "    # Optimizer\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    # EarlyStopping Callback erstellen\n",
        "    early_stopping = EarlyStopping(\n",
        "      monitor='val_loss',  # Überwacht die Validierungs-Loss\n",
        "      patience=10,          # Stoppt, wenn sich die Loss für 5 Epochen nicht verbessert\n",
        "      restore_best_weights=True  # Stellt die besten Gewichte wieder her\n",
        "    )\n",
        "    history = model.fit(X_train, Y_train, epochs=20, batch_size=batch_size, validation_split=0.1, verbose=0, callbacks = [early_stopping])\n",
        "    historys.append(history)\n",
        "    params_.append([num_layers,neurons,learning_rate,batch_size,activation])\n",
        "    # Bewertung auf Testset\n",
        "    loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print(f\"Loss: {loss}; Accuracy: {accuracy}\")\n",
        "\n",
        "    return 1 - loss  # Wir minimieren loss\n",
        "\n",
        "# Bayesian Optimization starten\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "# Beste Hyperparameter ausgeben\n",
        "print(\"Beste Hyperparameter:\", study.best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b01986-f290-4695-d9ab-08bef38147cd",
        "id": "-9CDcBT1zDKM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 19:57:27,516] A new study created in memory with name: no-name-6e74af52-20e7-4280-a831-0bff2b93e8ba\n",
            "<ipython-input-24-6803860465e4>:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
            "[I 2025-02-01 19:57:51,895] Trial 0 finished with value: 0.0 and parameters: {'num_layers': 1, 'neurons': 512, 'learning_rate': 6.097150420496927e-05, 'batch_size': 608, 'activation': 'leaky_relu'}. Best is trial 0 with value: 0.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931487917900085; Accuracy: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 19:58:50,457] Trial 1 finished with value: 4.999999873689376e-05 and parameters: {'num_layers': 3, 'neurons': 128, 'learning_rate': 1.2399758341628846e-05, 'batch_size': 160, 'activation': 'relu'}. Best is trial 1 with value: 4.999999873689376e-05.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931495666503906; Accuracy: 4.999999873689376e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:07:04,972] Trial 2 finished with value: 0.020600000396370888 and parameters: {'num_layers': 5, 'neurons': 896, 'learning_rate': 0.00011485819454393576, 'batch_size': 928, 'activation': 'leaky_relu'}. Best is trial 2 with value: 0.020600000396370888.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931499242782593; Accuracy: 0.020600000396370888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:07:26,272] Trial 3 finished with value: 0.00019999999494757503 and parameters: {'num_layers': 1, 'neurons': 640, 'learning_rate': 9.279715960572855e-05, 'batch_size': 928, 'activation': 'relu'}. Best is trial 2 with value: 0.020600000396370888.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931590437889099; Accuracy: 0.00019999999494757503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:09:16,808] Trial 4 finished with value: 0.025699999183416367 and parameters: {'num_layers': 1, 'neurons': 640, 'learning_rate': 0.0004736625156364389, 'batch_size': 96, 'activation': 'leaky_relu'}. Best is trial 4 with value: 0.025699999183416367.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931623816490173; Accuracy: 0.025699999183416367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:09:44,252] Trial 5 finished with value: 0.00039999998989515007 and parameters: {'num_layers': 3, 'neurons': 128, 'learning_rate': 9.513587763807757e-05, 'batch_size': 608, 'activation': 'relu'}. Best is trial 4 with value: 0.025699999183416367.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931474208831787; Accuracy: 0.00039999998989515007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:11:34,459] Trial 6 finished with value: 4.999999873689376e-05 and parameters: {'num_layers': 5, 'neurons': 384, 'learning_rate': 5.779084822852027e-05, 'batch_size': 640, 'activation': 'relu'}. Best is trial 4 with value: 0.025699999183416367.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931480169296265; Accuracy: 4.999999873689376e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:18:51,044] Trial 7 finished with value: 0.0 and parameters: {'num_layers': 5, 'neurons': 768, 'learning_rate': 1.584792925578322e-05, 'batch_size': 352, 'activation': 'leaky_relu'}. Best is trial 4 with value: 0.025699999183416367.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931496858596802; Accuracy: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:22:15,895] Trial 8 finished with value: 0.0 and parameters: {'num_layers': 5, 'neurons': 512, 'learning_rate': 0.00013776461801664756, 'batch_size': 800, 'activation': 'relu'}. Best is trial 4 with value: 0.025699999183416367.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931502223014832; Accuracy: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:22:46,952] Trial 9 finished with value: 0.07175000011920929 and parameters: {'num_layers': 1, 'neurons': 384, 'learning_rate': 0.0009566255730068911, 'batch_size': 672, 'activation': 'relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931585073471069; Accuracy: 0.07175000011920929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:28:55,502] Trial 10 finished with value: 0.01510000042617321 and parameters: {'num_layers': 2, 'neurons': 1024, 'learning_rate': 0.0035371857117302797, 'batch_size': 384, 'activation': 'relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931650638580322; Accuracy: 0.01510000042617321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:32:25,894] Trial 11 finished with value: 0.001449999981559813 and parameters: {'num_layers': 2, 'neurons': 384, 'learning_rate': 0.001238615610928078, 'batch_size': 32, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931800246238708; Accuracy: 0.001449999981559813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:32:55,490] Trial 12 finished with value: 0.0006500000017695129 and parameters: {'num_layers': 1, 'neurons': 384, 'learning_rate': 0.0007929243851793348, 'batch_size': 416, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931629776954651; Accuracy: 0.0006500000017695129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:35:11,435] Trial 13 finished with value: 0.00860000029206276 and parameters: {'num_layers': 2, 'neurons': 640, 'learning_rate': 0.0006665805742897081, 'batch_size': 224, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931594014167786; Accuracy: 0.00860000029206276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:35:26,759] Trial 14 finished with value: 0.0 and parameters: {'num_layers': 1, 'neurons': 256, 'learning_rate': 0.007352554313715924, 'batch_size': 768, 'activation': 'relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931728720664978; Accuracy: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:40:17,271] Trial 15 finished with value: 4.999999873689376e-05 and parameters: {'num_layers': 4, 'neurons': 768, 'learning_rate': 0.0003877230295826665, 'batch_size': 512, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931548118591309; Accuracy: 4.999999873689376e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:50:46,313] Trial 16 finished with value: 0.0 and parameters: {'num_layers': 2, 'neurons': 768, 'learning_rate': 0.002479473734605494, 'batch_size': 32, 'activation': 'relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6932039260864258; Accuracy: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:51:06,594] Trial 17 finished with value: 0.0001500000071246177 and parameters: {'num_layers': 1, 'neurons': 256, 'learning_rate': 0.00027356302024072635, 'batch_size': 768, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931524276733398; Accuracy: 0.0001500000071246177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:55:46,870] Trial 18 finished with value: 0.0 and parameters: {'num_layers': 4, 'neurons': 512, 'learning_rate': 0.0016963782796940924, 'batch_size': 224, 'activation': 'relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931551694869995; Accuracy: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:57:21,011] Trial 19 finished with value: 0.0 and parameters: {'num_layers': 2, 'neurons': 640, 'learning_rate': 0.00031034911800942625, 'batch_size': 480, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.693151593208313; Accuracy: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 20:57:58,225] Trial 20 finished with value: 0.0 and parameters: {'num_layers': 3, 'neurons': 256, 'learning_rate': 0.006759872398299211, 'batch_size': 1024, 'activation': 'relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931756138801575; Accuracy: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 21:06:56,559] Trial 21 finished with value: 0.0 and parameters: {'num_layers': 4, 'neurons': 1024, 'learning_rate': 0.00021708502557214032, 'batch_size': 896, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931502819061279; Accuracy: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 21:13:26,080] Trial 22 finished with value: 0.00019999999494757503 and parameters: {'num_layers': 4, 'neurons': 896, 'learning_rate': 2.9596756844884063e-05, 'batch_size': 1024, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931476593017578; Accuracy: 0.00019999999494757503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 21:14:12,358] Trial 23 finished with value: 0.020999999716877937 and parameters: {'num_layers': 1, 'neurons': 896, 'learning_rate': 0.0006334963620327914, 'batch_size': 704, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.693168580532074; Accuracy: 0.020999999716877937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 21:14:56,397] Trial 24 finished with value: 0.05429999902844429 and parameters: {'num_layers': 1, 'neurons': 896, 'learning_rate': 0.000746578114443129, 'batch_size': 672, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931657791137695; Accuracy: 0.05429999902844429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 21:15:38,775] Trial 25 finished with value: 0.03395000100135803 and parameters: {'num_layers': 1, 'neurons': 768, 'learning_rate': 0.001119614196155162, 'batch_size': 576, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931583881378174; Accuracy: 0.03395000100135803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 21:18:13,652] Trial 26 finished with value: 4.999999873689376e-05 and parameters: {'num_layers': 2, 'neurons': 896, 'learning_rate': 0.0012296141743195015, 'batch_size': 672, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931617259979248; Accuracy: 4.999999873689376e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 21:19:05,450] Trial 27 finished with value: 0.023099999874830246 and parameters: {'num_layers': 1, 'neurons': 768, 'learning_rate': 0.0036453093289126443, 'batch_size': 576, 'activation': 'leaky_relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.693181574344635; Accuracy: 0.023099999874830246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 21:23:17,058] Trial 28 finished with value: 0.04194999858736992 and parameters: {'num_layers': 2, 'neurons': 1024, 'learning_rate': 0.0010905786942030234, 'batch_size': 832, 'activation': 'relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931551098823547; Accuracy: 0.04194999858736992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-01 21:29:04,560] Trial 29 finished with value: 0.0 and parameters: {'num_layers': 2, 'neurons': 1024, 'learning_rate': 0.002329401745700488, 'batch_size': 864, 'activation': 'relu'}. Best is trial 9 with value: 0.07175000011920929.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6931600570678711; Accuracy: 0.0\n",
            "Beste Hyperparameter: {'num_layers': 1, 'neurons': 384, 'learning_rate': 0.0009566255730068911, 'batch_size': 672, 'activation': 'relu'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "Ucep0aD9a_xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9996b168-5737-4aed-e784-95bc82431cbe",
        "id": "ivE5ddSTzDKL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.4/383.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.0\n"
          ]
        }
      ]
    }
  ]
}